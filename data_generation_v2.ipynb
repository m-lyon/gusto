{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# This notebook generates data using only full (all 4 months, non zero values) as training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/3-9-48-72months_383CpGs_153indivs_age_related.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_df_to_dict(df, unique_ids, sorted_probeids=None, sorted_months=None):\n",
    "    filtered_df = df[df['ID'].isin(unique_ids)]\n",
    "\n",
    "    # Get unique ProbeIDs and timepoints\n",
    "    sorted_probeids = sorted_probeids if sorted_probeids is not None else np.sort(df['ProbeID'].unique())\n",
    "    sorted_months = sorted_months if sorted_months is not None else np.sort(df['Months'].unique())\n",
    "\n",
    "    # Create a dictionary to store the data\n",
    "    data = {}\n",
    "\n",
    "    # Create a dictionary to map ProbeID and Months to their indices\n",
    "    probeid_to_idx = {probeid: idx for idx, probeid in enumerate(sorted_probeids)}\n",
    "    month_to_idx = {month: idx for idx, month in enumerate(sorted_months)}\n",
    "\n",
    "    # Initialize arrays in the dictionary for each ID\n",
    "    for id_val in unique_ids:\n",
    "        data[id_val] = {}\n",
    "        data[id_val]['data'] = np.zeros((len(sorted_probeids), len(sorted_months)), dtype=np.float32)\n",
    "        data[id_val]['mask'] = np.zeros((len(sorted_probeids), len(sorted_months)), dtype=int)\n",
    "        data[id_val]['time'] = np.zeros((len(sorted_months), 1), dtype=np.float32)\n",
    "\n",
    "    # Fill in the array with Output values\n",
    "    for _, row in filtered_df.iterrows():\n",
    "        id_val, probe_id, month, inputs, output = row['ID'], row['ProbeID'], row['Months'], row['Input'], row['Output']\n",
    "        \n",
    "        # Get the index for ProbeID and Months\n",
    "        probe_idx = probeid_to_idx[probe_id]\n",
    "        month_idx = month_to_idx[month]\n",
    "\n",
    "        if np.isnan(output):\n",
    "            continue\n",
    "\n",
    "        # Assign the output value to the correct position\n",
    "        data[id_val]['data'][probe_idx, month_idx] = output\n",
    "        data[id_val]['mask'][probe_idx, month_idx] = 1\n",
    "        if data[id_val]['time'][month_idx] == 0:\n",
    "            data[id_val]['time'][month_idx] = inputs\n",
    "\n",
    "    return {'data': data, 'probeids': sorted_probeids, 'months': sorted_months}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Check if each unique ID has all 4 months\n",
    "months = {3, 9, 48, 72}\n",
    "valid_ids_months = df.groupby('ID')['Months'].apply(lambda x: set(x) == months)\n",
    "# Step 2: Check if each unique ID has all 383 unique ProbeIDs\n",
    "unique_probeids = set(df['ProbeID'].unique())\n",
    "valid_ids_probeids = df.groupby('ID')['ProbeID'].apply(lambda x: set(x) == unique_probeids)\n",
    "# Step 3: Check if each unique ID has non-zero values for Input & Output\n",
    "valid_ids_non_zero_input = df.groupby('ID')['Input'].apply(lambda x: (x > 0).all())\n",
    "valid_ids_non_zero_output = df.groupby('ID')['Output'].apply(lambda x: (x > 0).all())\n",
    "valid_ids = valid_ids_months & valid_ids_probeids & valid_ids_non_zero_input & valid_ids_non_zero_output\n",
    "valid_ids.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an rng state\n",
    "rng = np.random.default_rng(42)\n",
    "# Get the unique IDs within the df\n",
    "unique_subj_ids = df['ID'].unique()[valid_ids]\n",
    "\n",
    "# Shuffle the unique IDs\n",
    "rng.shuffle(unique_subj_ids)\n",
    "# Split into train (80%), validation (10%), and test (10%) sets\n",
    "train_ids = unique_subj_ids[:int(0.9*len(unique_subj_ids))]\n",
    "val_ids = unique_subj_ids[int(0.9*len(unique_subj_ids)):]\n",
    "# Split the df into train, validation, and test sets\n",
    "train_df = df[df['ID'].isin(train_ids)]\n",
    "val_df = df[df['ID'].isin(val_ids)]\n",
    "# Create a data structure consisting of a dictionary of ids, ProbeID, and timepoints, for each dataset\n",
    "train_dict = convert_df_to_dict(df, train_ids)\n",
    "val_dict = convert_df_to_dict(df, val_ids, train_dict['probeids'], train_dict['months'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the data structure to a pickle file\n",
    "with open('data/3-9-48-72months_383CpGs_153indivs_train_nomissing.pkl', 'wb') as f:\n",
    "    pickle.dump(train_dict, f)\n",
    "with open('data/3-9-48-72months_383CpGs_153indivs_val_nomissing.pkl', 'wb') as f:\n",
    "    pickle.dump(val_dict, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['020-00043', '010-20797'], dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gusto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
